{
    "talks": [   {
        "state": "accepted",
        "authors": [
            {
                "email": "ewoudvc@gmail.com",
                "fullname": "Ewoud Van Craeynest",
                "first_name": "Ewoud",
                "last_name": "Van Craeynest"
            }
        ],
        "title": "Asynchronous programming with Coroutines in Python",
        "has_description": false,
        "hour": "14:00",
        "progress": "confirmed",
        "notes": "Presentation 80% finished (as of 27/10/2016)",
        "subtitle": "A gentle introduction",
        "abstract": "A talk about async programming, touching briefly on the history & Python3.4 before moving on to introducing async/await in Python3.5 (and how to test)\nBriefly mentions curio by DaBeaz.",
        "has_abstract": true,
        "description": "",
        "duration": "00:30:00",
        "room": "UD2.120 (Chavanne)",
        "day": "2017-02-05 Sunday",
        "event_type": "Lecture",
        "exact_duration": false,
        "talk_id": "4897"
    },
    {
        "state": "accepted",
        "authors": [
            {
                "email": "martius@martiusweb.net",
                "fullname": "Martin Richard",
                "first_name": "Martin",
                "last_name": "Richard"
            }
        ],
        "title": "asynctest",
        "has_description": true,
        "hour": "16:00",
        "progress": "confirmed",
        "notes": "I gave a similar talk at PyConFR last october (I provided a link to the slides with the submission).\nIf I give this talk during FOSDEM, I will focus more on asyncio related content than at PyConFR, where the talk targeted a broader audience (including folks less familiar with event loops, asynchronous programming, etc).",
        "subtitle": "easier testing of asyncio code",
        "abstract": "asynctest enhances the standard python package unittest with features for asyncio. This talk aims at presenting asynctest and discuss various practices around unit testing of code using asyncio.",
        "has_abstract": true,
        "description": "This talk aims at presenting asynctest, a library written on top of the standard unittest module. asynctest provides features for writing tests for libraries and programs using asyncio.\n\nWe will discover handy features like:\n\n  * how asynctest.TestCase reduces boilerplate and offers safeguards around subtle mistakes in an asynchronous code,\n  * how asynctest.Mock objects helps to mock coroutines, and how patch decorators are enhanced to handle coroutines,\n  * how one can control the event loop's clock.\n\nI will also discuss the future of asynctest and planned features.",
        "duration": "00:30:00",
        "room": "UD2.120 (Chavanne)",
        "day": "2017-02-05 Sunday",
        "event_type": "",
        "exact_duration": false,
        "talk_id": "5717"
    },
    {
        "state": "accepted",
        "authors": [
            {
                "email": "flub@devork.be",
                "fullname": "Floris Bruynooghe",
                "first_name": "Floris",
                "last_name": "Bruynooghe"
            }
        ],
        "title": "Cloud Native Python",
        "has_description": false,
        "hour": "13:00",
        "progress": "confirmed",
        "notes": "",
        "subtitle": "",
        "abstract": "Serverside applications are more and more likely to need to run in\ndynamic cloud environments where they can automatically scale as\nrequired.  One rightfully popular approach is to run the application\nas a Docker container inside a Kubernetes cluster, giving you a lot of\noperational benefits thanks to the Kubernetes folks.\n\nFor the most part it is rather easy to make your Python application\nwork inside a Docker container.  But there are a number of common\npatterns one can follow to save time by delegating more things to the\nruntime environment.  Furthermore you can start adding a few simple\nnon-intrusive features to your application which will help improve the\napplication live-cycle in the cluster, ensuring smooth hand-over when\nmigrating the container to different nodes or scaling it up or down.\n\nThis talk will discuss how to write a Python application which will\nbehave well in this environment, starting with the basics steps you\ncan rely on the runtime for, covering logging and all the way to\nsupporting the service life-cycle, health checking and monitoring in a\nKubernetes environment.  You will see that building a cloud-native\napplication is not very hard and something you can gradually\nintroduce.",
        "has_abstract": true,
        "description": "",
        "duration": "00:30:00",
        "room": "UD2.120 (Chavanne)",
        "day": "2017-02-05 Sunday",
        "event_type": "Lecture",
        "exact_duration": false,
        "talk_id": "5758"
    },
    {
        "state": "accepted",
        "authors": [
            {
                "email": "bmbouter@gmail.com",
                "fullname": "Brian Bouterse",
                "first_name": "Brian",
                "last_name": "Bouterse"
            }
        ],
        "title": "Debugging Hung Python Processes with GDB",
        "has_description": true,
        "hour": "13:30",
        "progress": "confirmed",
        "notes": "I plan to present and show interactive examples.",
        "subtitle": "",
        "abstract": "When things go wrong in production, it can be necessary to troubleshoot problems where they occur, instead of in a development environment. In those situations having a working knowledge of GDB, GDB Python Extensions, and strace is very helpful. You will see some  simple techniques to get insight into those situations. This talk  outlines several techniques for connecting to an already running, \"stuck\", or deadlocked Python process using GDB for debugging.\n\nDuring the talk, we will:\n\n* inspect the current state of threads with\n* use and demo the GDB macros for Python\n* inspect a locally running process and a core dump collected from a remote machine\n* use strace to gather system call information about a process\n* discuss  the SIGTRAP handler as a proactive way to make rpdb available in production.\n\nI have had to debug several hard-to-find bugs that were very infrequent deadlocks using Python. Furthermore it was happening on remote machines I could not have network access to. This technique was invaluable in those situations.",
        "has_abstract": true,
        "description": "Everything is in the abstract",
        "duration": "00:30:00",
        "room": "UD2.120 (Chavanne)",
        "day": "2017-02-05 Sunday",
        "event_type": "Lecture",
        "exact_duration": false,
        "talk_id": "5757"
    },
    {
        "state": "accepted",
        "authors": [
            {
                "email": "jgb@bitergia.com",
                "fullname": "Jesus M. Gonzalez-Barahona",
                "first_name": "Jesus M.",
                "last_name": "Gonzalez-Barahona"
            }
        ],
        "title": "GrimoireLab",
        "has_description": true,
        "hour": "11:30",
        "progress": "confirmed",
        "notes": "",
        "subtitle": "a Python toolset for software development analytics",
        "abstract": "The talk will explain how to analyze software development repositories of common use in the free software community with [GrimoireLab tools][http://grimoirelab.github.io], a toolset for software development analytics writting in Python. It will start by explaining how to retrieve data from git, Bugzilla, GitHub, mailing lists, StackOverflow, Gerrit, and many other repositories by, and organizing it in a database. The talk will later explain how this database can be exploited with several components of the toolset, for different purposes. In this context, special attention will be given to how to extract useful information from it using Python/Pandas and iPython/Jupyter Notebooks; and how to use ElasticSearch/Kibana to deploy actionable dashboards that show data in all its glory.",
        "has_abstract": true,
        "description": "Many free / open source software (FOSS) projects feature an open development model, with public software development repositories which anyone can browse. These repositories are normally used to find specific information, such a certain commit or a particular bug report. But they can also be mined to extract all relevant data, so that it can be analyzed later to learn about any specific or general aspect of the project. This talk will explain the GrimoireLab method for doing that, which is based on organizing all that information in a database, which can be later analyzed. This approach allows for minimal impact on the project infrastructure, since data is retrieved only once, even if it later analyzed many times. It allows as well for efficiency and comfort when mining data for an analysis, since the results are readily available, databases can be shared and replicated at will, and queried them with any kind of tools is easy.\n\nThe tools that retrieve information from the repositories are grouped in the GrimoireLab toolset. It includes mature, widely tested programs capable of extracting information from most repositories used by FOSS projects of any scale. Many of them are agnostic with respect to the database used, although currently ElasticSearch is the best supported.\n\nThe produced databases can be exploited in several ways, of which two will be explained during the talk: using Python/Pandas to produce iPython/Jupyter Notebooks which analyze some aspect of the project; and using Python to feed a ElasticSearch cluster, with a Kibana front-end for visualizing in a flexible, powerful dashboard.\n\nAll these approaches can be used to understand general aspects of the project, such as how efficient are the code review or bug fixing processes, how diverse are contributions to the git repository, or how conversations in mailing lists or StackOverflow are shaped. But they can be used as well to drill down, and analyze the contributions by a certain developer, or the longer code review processes, or the contents of the most lively email and QA threads.\n\nThe talk will explain the whole process from data retrieval to visualization, and will show some specific cases of real world use, such as the dashboards produced for Eclipse, OPNFV, MediaWiki and many others. Some of the contents of the talk are described in detail in the online book GrimoireLab Training.",
        "duration": "00:30:00",
        "room": "UD2.120 (Chavanne)",
        "day": "2017-02-05 Sunday",
        "event_type": "",
        "exact_duration": false,
        "talk_id": "5506"
    },
    {
        "state": "accepted",
        "authors": [
            {
                "email": "y.gravrand@gmail.com",
                "fullname": "Yann Gravrand",
                "first_name": "Yann",
                "last_name": "Gravrand"
            }
        ],
        "title": "Hacking midi devices with StepPy",
        "has_description": false,
        "hour": "11:00",
        "progress": "confirmed",
        "notes": "",
        "subtitle": "a step sequencer in Python",
        "abstract": "If you're making electronic music in 2017, you're likely to have seen or used one of Native Instrument's \"Maschine\", \"Maschine Jam\", Novation's \"Circuit\", or Ableton's \"Push\"...\nThese pad-based devices allow musicians to trigger samples, and create rhythms intuitively by the means of a \"step sequencer\".\nThe said step sequencer is implemented in the box and stays in it...\n\nThanks to \"mido\" and \"portmidi\" libraries, I designed a lightweight open source software sequencer (without a GUI), exposing abstractions for python programmers to use their existing MIDI-enabled hardware. My MiniNova, Launch Control and Quneo devices were hacked this way to create new functionality together.\n\nThe talk starts with a quick explanation of MIDI and step sequencing, then describes the benefits and challenges of using Python in this context, as well as the choice of gevent against other async frameworks. It ends of course with a live demo!",
        "has_abstract": true,
        "description": "",
        "duration": "00:30:00",
        "room": "UD2.120 (Chavanne)",
        "day": "2017-02-05 Sunday",
        "event_type": "",
        "exact_duration": false,
        "talk_id": "5749"
    },
    {
        "state": "accepted",
        "authors": [
            {
                "email": "victor.stinner@gmail.com",
                "fullname": "Victor Stinner",
                "first_name": "Victor",
                "last_name": "Stinner"
            }
        ],
        "title": "How to run a stable benchmark",
        "has_description": true,
        "hour": "15:00",
        "progress": "confirmed",
        "notes": "Working on optimizations is a task more complex than expected on the first look. Any optimization must be measured to make sure that, in practice, it speeds up the application task. Problem: it is very hard to obtain stable benchmark results.\n\nThe stability of a benchmark (performance measurement) is essential to be able to compare two versions of the code and compute the difference (faster or slower?). An unstable benchmark is useless, and is a risk of giving a false result when comparing performance which could lead to bad decisions.\n\nI'm gonna show you the Python project \"perf\" which helps to launch benchmarks, but also to analyze them: compute the mean and the standard deviation on multiple runs, render an histogram to visualize the probability curve, compare between multiple results, run again a benchmark to collect more samples, etc.\n\nThe use case is to measure small isolated optimizations on CPython and make sure that they don't introduce performance regression in term of performance.",
        "subtitle": "",
        "abstract": "",
        "has_abstract": false,
        "description": "Working on optimizations is a task more complex than expected on the first look. Any optimization must be measured to make sure that, in practice, it speeds up the application task. Problem: it is very hard to obtain stable benchmark results.\n\nThe stability of a benchmark (performance measurement) is essential to be able to compare two versions of the code and compute the difference (faster or slower?). An unstable benchmark is useless, and is a risk of giving a false result when comparing performance which could lead to bad decisions.\n\nI'm gonna show you the Python project \"perf\" which helps to launch benchmarks, but also to analyze them: compute the mean and the standard deviation on multiple runs, render an histogram to visualize the probability curve, compare between multiple results, run again a benchmark to collect more samples, etc.\n\nThe use case is to measure small isolated optimizations on CPython and make sure that they don't introduce performance regression in term of performance.",
        "duration": "00:30:00",
        "room": "UD2.120 (Chavanne)",
        "day": "2017-02-05 Sunday",
        "event_type": "Lecture",
        "exact_duration": false,
        "talk_id": "5762"
    },
    {
        "state": "accepted",
        "authors": [
            {
                "email": "sahildua2305@gmail.com",
                "fullname": "Sahil Dua",
                "first_name": "Sahil",
                "last_name": "Dua"
            }
        ],
        "title": "Introduction to Pandas",
        "has_description": true,
        "hour": "09:00",
        "progress": "confirmed",
        "notes": "",
        "subtitle": "Introduction to the open source data analysis and manipulation library",
        "abstract": "This talk will be based on open source data manipulation and analysis python library – Pandas. It will mainly focus on exploring the most commonly used features of the library like – integrated indexing using DataFrame objects, slicing and subsetting of large data sets, merging, joining and size mutability of data structures, hierarchical axis indexing to work with high-dimensional data in a lower-dimensional data, flexible reshaping and pivoting of data sets etc.",
        "has_abstract": true,
        "description": "This talk will be based on open source data manipulation and analysis python library – Pandas. It will mainly focus on exploring the most commonly used features of the library like – integrated indexing using DataFrame objects, slicing and subsetting of large data sets, merging, joining and size mutability of data structures, hierarchical axis indexing to work with high-dimensional data in a lower-dimensional data, flexible reshaping and pivoting of data sets etc.",
        "duration": "00:30:00",
        "room": "UD2.120 (Chavanne)",
        "day": "2017-02-05 Sunday",
        "event_type": "Lecture",
        "exact_duration": false,
        "talk_id": "5478"
    },
    {
        "state": "accepted",
        "authors": [
            {
                "email": "etingof@gmail.com",
                "fullname": "Ilya Etingof",
                "first_name": "Ilya",
                "last_name": "Etingof"
            }
        ],
        "title": "Introduction to pyasn1",
        "has_description": true,
        "hour": "16:30",
        "progress": "confirmed",
        "notes": "Being a primary author of the *pyasn1* package, I'm qualified to present this topic and handle both general and very hands-on discussion.",
        "subtitle": "Handling ASN.1-based protocols in Python",
        "abstract": "The [ASN.1](https://en.wikipedia.org/wiki/Abstract_Syntax_Notation_One) technology will be briefly explained followed by the introduction to the [pyasn1 package](https://github.com/etingof/pyasn1), its  typical use cases and key features.",
        "has_abstract": true,
        "description": "Many data formats and network protocols now days base on [ASN.1](https://en.wikipedia.org/wiki/Abstract_Syntax_Notation_One). Python developers sometimes encounter binary blobs of ASN.1 data structures which they may want to analyze or modify anyhow.\n\nPythonistas who work with network protocols and data formats will hopefully find this talk educational and inspiring. The key take away would be a general understanding how *pyasn1* can solve most of their ASN.1 needs, despite seemingly bulky technology behind ASN.1.",
        "duration": "00:30:00",
        "room": "UD2.120 (Chavanne)",
        "day": "2017-02-05 Sunday",
        "event_type": "Lecture",
        "exact_duration": false,
        "talk_id": "5364"
    },
    {
        "state": "accepted",
        "authors": [
            {
                "email": "mariocj89@gmail.com",
                "fullname": "Mario Corchero",
                "first_name": "Mario",
                "last_name": "Corchero"
            }
        ],
        "title": "It's time for datetime",
        "has_description": true,
        "hour": "12:00",
        "progress": "confirmed",
        "notes": "Outline\n=======\nThe talk is walks around some facts that can trigger issues if some basic tips are not followed and well understood. Each of the facts will present the issue and how to avoid it. After going through all the \"facts and tips\" we will have overview in a single slide all the tips covered to consolidate them.\n\n- Concepts behind datetime (8m)\n    - What is a timestamp (datetime instance) (1m)\n    - The different lines of time (And what is a second) (5m)\n        - The consistency problem & history of time (30s)\n        - UT1 (30s) \n        - ITA(30s) \n        - Wall Time(30s)\n        - CPU Time(30s)\n        - UTC(60s)\n - Facts & Tips (10m)\n    - Time is relative (timezones) (2m)\n        - Don't use naive datetimes\n    - Time might not be monotonic and ascending (DST) (2m)\n        - Use non DST timezones (UTC+00:00 if possible)\n    - timezones change (1m) \n        - Keep up to date the timezone info\n    - You cannot \"just send\" datetimes (2m)\n        - Serialize using strings and ints\n    - time arithmetics can be tricky * (2m)\n        - Work in UTC & normalize\n- Take home tips (3m) \n- Common mistakes working with datetime* (4m)\n- Advanced topics* (5m)\n- Leap second\n- NTP (And how the time is perceived in your PC)\n- Useful libraries (30s)\n- Q&A (5m)\n\nThe sections with * means a bridge sections. Those can be skipped without the audience realizing about them to control the time of the talk. This way the talk adapts to the time being consumed and unexpected issues that may sink time or skipping without realizing some explanation and getting out of material.\n\nSome further details about the content\n--------------------------------------\n\nThe talk stats with some basic concepts aroud time. This sets the base for the issue with time and why everything is so hard around it when trying to represent absolutes points in time. The measure of second, the key of time and what datetime can represent, can be based on the earth rotation (UT1), on atomic processes (ITA), on the clock of your kitchen machinery or in the interrupts received at your CPU from a [PIT](https://en.wikipedia.org/wiki/Programmable_interval_timer).\n\nOnce we understand the different ways to see the time pass and acknowledge UTC we can jump into the common issues. This section will explain some tricky concepts about datetime and give a simple rule to be able to avoid it.  As an example we will start understanding that there are many relatives (naive) times that represent the same absolute (tz aware) time, the takeaway from this fact is that relatives times should be avoided when working with timestamps as they are ambiguous since they rely on a “default timezone”. The second “fact and rule” will be around DST, explaining how the “line of time” is not continuous in DST aware timezones. Here the rule to use only UTC avoids issues when building and working with time (explaining them and pointers to further details).\n\nThe “fact and rule” sections continues until the wrap up where we brief all the rules as a list of tips to *stop the pain when suffering with datetime*.\n\nThe talk continues with small snippets that show common mistakes, which show how is a bad idea not to follow the outlined rules and are easy to understand with the previous knowledge. We close with a brief introduction and pointers to some advanced topics and libraries.",
        "subtitle": "Painless working with time in python",
        "abstract": "Working with time is not a trivial challenge. Python includes a native module in the standard library to work with it but datetime keeps being together with unicode a common source of errors. This often leads to the widespread of many other libraries in the attempt of easing the work of working with datetime. Datetime is one of those API that looks easy to use but given the many concepts around time, is it easy to get backfired if the developer has not solid knowledge about the them.\n\nIn this talk we will overview the main concepts about timestamps represented through datetime objects, the limitations on the standard library and some simple steps to try to avoid the common mistakes that everyone can fall into.\n\nNaive datetimes (which the datetime API works by default with) are a great tool to represent calendar times, but when talking about timestamps (focus of this talk) timezones is n essential part of it and the datetime module can be tricky to use for that use cases.\n\nWe will also speak about different standards of time, time zones, Daylight Saving Times, leap seconds, serialization and datetime arithmetics.\n\nThe talk will be focused on giving the foundations that everyone knows to be able to understand and work efficiently and without making painful mistakes when dealing with time related algorithms.",
        "has_abstract": true,
        "description": "Audience\n========\n\nAll developers face a time when they have to work with datetime. This is clearly not a simple domain to just jump in to. The talk will help beginners and intermediate developers to understand and don’t subestimate the complexity of working with time. The most experiences developers will also have some take aways and pointers to further their grasp of this tricky field and gain confidence on their daily usage of time related libraries.\n\nThe talk will include explanations of what “time” actually means and how can we represent it in python. You don't need to be an expert in datetime nor ISO standards, the attendees will leave understanding the complexity of time, the main concepts behind datetime and a list of tips to represent timestamps with datetime in a painless way. The talk will also include pointers to solutions for more complex problems like leap seconds, the [fold attribute](https://www.python.org/dev/peps/pep-0495/), etc.\n\nKey Takeaways:\n- Calendar time vs Timestamps\n- Representations of time\n- Core ideas and tips around using datetime\n- Pointers to advanced topics",
        "duration": "00:30:00",
        "room": "H.1308 (Rolin)",
        "day": "2017-02-04 Saturday",
        "event_type": "Lecture",
        "exact_duration": false,
        "talk_id": "5421"
    },
    {
        "state": "accepted",
        "authors": [
            {
                "email": "rb.proj@gmail.com",
                "fullname": "Reimar  Bauer",
                "first_name": "Reimar ",
                "last_name": "Bauer"
            }
        ],
        "title": "MSS - Software for planning research aircraft missions",
        "has_description": true,
        "hour": "11:00",
        "progress": "confirmed",
        "notes": "",
        "subtitle": "",
        "abstract": "Scientific aircraft research flights have to be planned beforehand. For that it is necessary to have model forecasts of relevant quantities such as meteorological parameters, chemical composition or particle information to guide the aircraft to the location of interest.\nWe develop the MSS Project to make decissions easier where to investigate.",
        "has_abstract": true,
        "description": "Scientific aircraft research flights have to be planned beforehand. For that it is necessary to have model forecasts of relevant quantities such\nas meteorological parameters, chemical composition or particle information to guide the aircraft to the location of interest.\nTypically, many scientific instruments on board those aircrafts used to investigate e.g. the chemical composition of the air in order to get new insights often with the involvement of different science groups.\n\nFor discussion of the possibilites of the research flights, the Mission Support System (MSS) was developed. This software helps to review a big\namount of metereological and model data by viewing the forecasted parameters of interest along possible regions of a proposed flight path.\nData and possible flight paths can be displayed on a hoizontal view (map projection) or on a vertical view (along the proposed flight path).\nFlight paths can be constructed and modified on these views. Exchange through a waypoint table is also possible.\n\nThe talk gives a brief insight into the MSS software development current state.\n\nWe are using the OWS interface standard. https://geopython.github.io/OWSLib/\nMSS is a client/server application. The QT client interacts with a paste wsgi server.\nThe software is available for all platforms on conda-forge.",
        "duration": "00:30:00",
        "room": "H.1308 (Rolin)",
        "day": "2017-02-04 Saturday",
        "event_type": "Lecture",
        "exact_duration": false,
        "talk_id": "5766"
    },
    {
        "state": "accepted",
        "authors": [
            {
                "email": "jmoc25@gmail.com",
                "fullname": "José Manuel Ortega",
                "first_name": "José Manuel",
                "last_name": "Ortega"
            }
        ],
        "title": "OSINT Tools for Security Auditing",
        "has_description": true,
        "hour": "13:30",
        "progress": "confirmed",
        "notes": "",
        "subtitle": "Open Source Intelligence with python tools",
        "abstract": "The talk would aim about making an introduction to open source intelligence automation tools(OSINT)  developed in Python, commenting the process we can follow to obtain, analyze and exploit \npublic information in social networks and public servers.The final objective is obtain the  maximum possible of knowledge in the context we are auditing.\n\nThe talking points could be:\n\n-Introduction searching information from multiples sources with OSINT tools.\n-OSINT tools developed with python for extracting public information from servers and domains.\n-Advantages and limitations these tools from the user point of view.\n-Comment how these tools are developed and the main modules used in their development.",
        "has_abstract": true,
        "description": "Some of the tools to comment are:\n\n-Censys and Shodan Python API as search engine server information.\n-SpiderFoot and recon-ng as a tools for extracting information from multiple sources and automate the footprinting process.\n-the Harvester as Python script for extracting emails and hostnames in a particular domain.\n-Osrframework and Maltego OSINT visualisation tool\n-Libraries and modules for collecting information from Tor and ZeroNet networks\n-Tinfoleak and Tweepy as Python scripts for data extraction on twitter.\n-FullContact API for obtain social networks profiles associated with an email address.",
        "duration": "00:30:00",
        "room": "H.1308 (Rolin)",
        "day": "2017-02-04 Saturday",
        "event_type": "Other",
        "exact_duration": false,
        "talk_id": "5041"
    },
    {
        "state": "accepted",
        "authors": [
            {
                "email": "jonathan@slenders.be",
                "fullname": "Jonathan Slenders",
                "first_name": "Jonathan",
                "last_name": "Slenders"
            }
        ],
        "title": "prompt_toolkit",
        "has_description": true,
        "hour": "15:30",
        "progress": "confirmed",
        "notes": "Two years ago at Fosdem 2015, I presented prompt_toolkit, a library for building command line applications.\nA lot of progress was made, and it became the foundation for the UI in many tools, including IPython, http-prompt, xonsh and others.\n\nDuring this talk, we'll have a look at how prompt_toolkit progressed, how it became successful, how it created a community/ecosystem of many new command line applications, and the future.",
        "subtitle": "two years later",
        "abstract": "Two years ago at Fosdem 2015, I presented prompt_toolkit, a library for building command line applications.\nA lot of progress was made, and it became the foundation for the UI in many tools, including IPython, http-prompt, xonsh and others.\n\nDuring this talk, we'll have a look at how prompt_toolkit progressed, how it became successful, how it created a community/ecosystem of many new command line applications, and the future.",
        "has_abstract": true,
        "description": "Two years ago at Fosdem 2015, I presented prompt_toolkit, a library for building command line applications.\nA lot of progress was made, and it became the foundation for the UI in many tools, including IPython, http-prompt, xonsh and others.\n\nDuring this talk, we'll have a look at how prompt_toolkit progressed, how it became successful, how it created a community/ecosystem of many new command line applications, and the future.",
        "duration": "00:30:00",
        "room": "UD2.120 (Chavanne)",
        "day": "2017-02-05 Sunday",
        "event_type": "Lecture",
        "exact_duration": false,
        "talk_id": "5409"
    },
    {
        "state": "accepted",
        "authors": [
            {
                "email": "jonathan@slenders.be",
                "fullname": "Jonathan Slenders",
                "first_name": "Jonathan",
                "last_name": "Slenders"
            }
        ],
        "title": "Python and \"the SOLID principles\"",
        "has_description": true,
        "hour": "09:30",
        "progress": "confirmed",
        "notes": "This is a second talk that I submit for Fosdem.\nProbably, it won't be possible to cover all the five principles in just half an hour, but I want to include at least the \"s\", \"o\" and the \"d\". I need to prepare this one a bit more in order to see what is doable in half an hour. This talk is going to be great! :-)\n\n(If there are enough slots available, I think both talks are appropriate and interesting enough.)",
        "subtitle": "",
        "abstract": "Python and \"the SOLID principles\". This is an introduction to the first five principles named by Robert C. Martin (uncle Bob).\nThese principles are the foundation of a good software architecture. We will have a look at how this applies to Python code. We will have a look at abstract base classes, dependency inversion and so on.",
        "has_abstract": true,
        "description": "Python and \"the SOLID principles\". This is an introduction to the first five principles named by Robert C. Martin (uncle Bob).\nThese principles are the foundation of a good software architecture. We will have a look at how this applies to Python code. We will have a look at abstract base classes, dependency inversion and so on.",
        "duration": "00:30:00",
        "room": "UD2.120 (Chavanne)",
        "day": "2017-02-05 Sunday",
        "event_type": "Lecture",
        "exact_duration": false,
        "talk_id": "5709"
    },
    {
        "state": "accepted",
        "authors": [
            {
                "email": "ben@raspberrypi.org",
                "fullname": "Ben Nuttall",
                "first_name": "Ben",
                "last_name": "Nuttall"
            }
        ],
        "title": "Python and Raspberry Pi",
        "has_description": true,
        "hour": "14:30",
        "progress": "confirmed",
        "notes": "I am Raspberry Pi's Community Manager, working at the Raspberry Pi Foundation in Cambridge, UK.\n\nI have given talks on this topic at EuroPython, PyConUK, Python San Sebastian, EuroSciPy, PyCon Russia, PyCon Ireland and more.\n\nI am the author of the GPIO Zero Python library, and contributor to Sense HAT and others.",
        "subtitle": "Physical computing, GPIO, HATs and IoT with Python",
        "abstract": "Introducing Python developers to the world of physical computing and IoT using Python on the Raspberry Pi.\n\nThere's great fun to be had using the Pi's GPIO pins to connect with the real world for home automation and IoT projects. Python libraries like GPIO Zero, Picamera and Sense HAT provide a simple interface to GPIO devices, HATs and more.\n\nI will demonstrate the possibilities and show the power of Python in this environment.",
        "has_abstract": true,
        "description": "The Raspberry Pi Foundation is working to put the power of digital making in the hands of people all over the world, and is well known for its series of small, cheap single board computers.\n\nThe Raspberry Pi runs a well supported Linux distro based on Debian, which ships with a variety of programming tools and educational software. Python is the main supported language on the platform, used in many educational resources, and many Python libraries exist for making the most of the Pi platform with other devices.\n\nI will cover:\n\n- Raspberry Pi Foundation mission\n- Raspberry Pi hardware specs\n- Raspbian desktop\n- GPIO pins\n- GPIO Zero (Python library)\n- Picamera\n- Astro Pi (ESA space mission) & Sense HAT\n- More HATs\n- Pi projects\n- Raspberry Pi community",
        "duration": "00:30:00",
        "room": "UD2.120 (Chavanne)",
        "day": "2017-02-05 Sunday",
        "event_type": "Lecture",
        "exact_duration": false,
        "talk_id": "5764"
    },
    {
        "state": "accepted",
        "authors": [
            {
                "email": "flavien.raynaud@gmail.com",
                "fullname": "Flavien Raynaud",
                "first_name": "Flavien",
                "last_name": "Raynaud"
            }
        ],
        "title": "Python Data Structures implementation",
        "has_description": true,
        "hour": "12:30",
        "progress": "confirmed",
        "notes": "",
        "subtitle": "list, dict, set: how does CPython actually implement them?",
        "abstract": "",
        "has_abstract": false,
        "description": "When writing Python code, you might find yourself using lists, dictionaries and even sets pretty often. But do you really know how they work?\nFortunately, their implementation as well as their history are (really) well documented.\nIn this presentation, we will dive into CPython 3.5 internals, explain how these data structures have been designed, how they behave (and why) and how they perform.",
        "duration": "00:30:00",
        "room": "UD2.120 (Chavanne)",
        "day": "2017-02-05 Sunday",
        "event_type": "",
        "exact_duration": false,
        "talk_id": "5392"
    },
    {
        "state": "accepted",
        "authors": [
            {
                "email": "baumann@rasdaman.com",
                "fullname": "Peter Baumann",
                "first_name": "Peter",
                "last_name": "Baumann"
            }
        ],
        "title": "Python Winding Itself Around Datacubes",
        "has_description": false,
        "hour": "10:30",
        "progress": "confirmed",
        "notes": "",
        "subtitle": "How to Access Massive Multi-Dimensional Arrays in a Pythonic Way",
        "abstract": "While python has developed into the lingua franca in Data Science there is often a paradigm break when accessing specialized tools. In particular for one of the core data categories in science and engineering, massive multi-dimensional arrays, out-of-memory solutions typically employ their own, different models.\n\nWe discuss this situation on the example of the scalable open-source array engine, rasdaman (\"raster data manager\") which offers access to and processing of Petascale multi-dimensional arrays through an SQL-style array query language, rasql. Such queries are executed in the server on a storage engine utilizing adaptive array partitioning and based on a processing engine implementing a \"tile streaming\" paradigm to allow processing of arrays massively larger than server RAM. The rasdaman QL has acted as blueprint for forthcoming ISO Array SQL and the Open Geospatial Consortium (OGC) geo analytics language, Web Coverage Processing Service, adopted in 2008. Not surprisingly, rasdaman is OGC and INSPIRE Reference Implementation for their \"Big Earth Data\" standards suite.\n\nRecently, rasdaman has been augmented with a python interface which allows to transparently interact with the database (credits go to Siddharth Shukla's Master Thesis at Jacobs University). Programmers do not need to know the rasdaman query language, as the operators are silently transformed, through lazy evaluation, into queries. Arrays delivered are likewise automatically transformed into their python representation.\n\nThe presenter is Principal Architect of rasdaman, editor of several \"Big Data\" standards, and co-chair of \"Big Data\" relevant working groups in several high-impact bodies. In the talk, the rasdaman concept will be illustrated with the help of large-scale real-life examples of operational satellite image and weather data services, and sample python code will be demonstrated live.",
        "has_abstract": true,
        "description": "",
        "duration": "00:30:00",
        "room": "H.1308 (Rolin)",
        "day": "2017-02-04 Saturday",
        "event_type": "Lecture",
        "exact_duration": false,
        "talk_id": "5588"
    },
    {
        "state": "accepted",
        "authors": [
            {
                "email": "brecht@mos6581.org",
                "fullname": "Brecht Machiels",
                "first_name": "Brecht",
                "last_name": "Machiels"
            }
        ],
        "title": "rinohtype - the Python document processor",
        "has_description": false,
        "hour": "14:00",
        "progress": "confirmed",
        "notes": "",
        "subtitle": "",
        "abstract": "rinohtype is a batch document processor that renders structured documents to PDF based on a document template and style sheet. rinohtype is written in Python 3 and supports CommonMark (Markdown) and reStructuredText input. A Sphinx builder is also provided that can produce PDFs from Sphinx projects, obviating the need for LaTeX.\n\nThe talk will present the design of rinohtype and illustrate how the style of documents can be easily customized using document templates and style sheets.",
        "has_abstract": true,
        "description": "",
        "duration": "00:30:00",
        "room": "H.1308 (Rolin)",
        "day": "2017-02-04 Saturday",
        "event_type": "",
        "exact_duration": false,
        "talk_id": "5760"
    },
    {
        "state": "accepted",
        "authors": [
            {
                "email": "revol@free.fr",
                "fullname": "François Revol",
                "first_name": "François",
                "last_name": "Revol"
            }
        ],
        "title": "Script the Web with Weboob",
        "has_description": true,
        "hour": "12:00",
        "progress": "confirmed",
        "notes": "",
        "subtitle": "Yes we can use the Web outside of Browsers",
        "abstract": "Weboob is a python framework for web scraping, providing command-line tools and GUI applications.\nIt supports several types of websites, from video collections to bug trackers, online banking or parcel tracking.",
        "has_abstract": true,
        "description": "The framework handles many types of website *capabilities* through various modules. The command-line tools allows scripting easily with several *formaters* (JSON, CSV...), but we can also use it as a python framework.\n\nWriting modules to support more websites is also very easy with the new Browser2 API.",
        "duration": "00:30:00",
        "room": "UD2.120 (Chavanne)",
        "day": "2017-02-05 Sunday",
        "event_type": "Lecture",
        "exact_duration": false,
        "talk_id": "5429"
    },
    {
        "state": "accepted",
        "authors": [
            {
                "email": "fridolin.pokorny@gmail.com",
                "fullname": "Fridolín Pokorný",
                "first_name": "Fridolín",
                "last_name": "Pokorný"
            }
        ],
        "title": "Selinon",
        "has_description": true,
        "hour": "10:30",
        "progress": "confirmed",
        "notes": "Selinon is a project that is based on popular Python project Celery. Celery is a distributed task queue that offers one to run tasks. Selinon gives one a power to define flows and dependencies in flows, schedule tasks based on results of workers, success or any external events, handle errors, trace flow state and actions in a distributed environment. Its main goal is to split task logic (code) and persistence logic from data and time dependencies between tasks in flows that are stated in simple YAML configuration files.",
        "subtitle": "Distributed dynamic task flow management with Python",
        "abstract": "Selinon is a project that is based on popular Python project Celery. Celery is a distributed task queue that offers one to run tasks. Selinon gives one a power to define flows and dependencies in flows, schedule tasks based on results of workers, success or any external events, handle errors, trace flow state and actions in a distributed environment. Its main goal is to split task logic (code) and persistence logic from data and time dependencies between tasks in flows that are stated in simple YAML configuration files.",
        "has_abstract": true,
        "description": "Selinon is an advanced flow management above Celery project (an asynchronous distributed task queue) written in Python3, that allows you to dynamically schedule tasks based on results of previous tasks, group tasks to flows, schedule flows from other flows, store results of tasks in your storages and databases transparently, validate results against defined JSON schemas, track flow progress via the build-in tracing mechanism, complex per-task or per-flow failure handling with fallback tasks or fallback flows and run the whole system in a distributed environments orchestrated by OpenShift or Kubernetes.",
        "duration": "00:30:00",
        "room": "UD2.120 (Chavanne)",
        "day": "2017-02-05 Sunday",
        "event_type": "",
        "exact_duration": false,
        "talk_id": "5451"
    },
    {
        "state": "accepted",
        "authors": [
            {
                "email": "julien@danjou.info",
                "fullname": "Julien Danjou",
                "first_name": "Julien",
                "last_name": "Danjou"
            }
        ],
        "title": "Storing metrics at scale with Gnocchi",
        "has_description": false,
        "hour": "10:00",
        "progress": "confirmed",
        "notes": "",
        "subtitle": "The Python based time series database",
        "abstract": "Gnocchi is a time series database written in Python, that has been created in the context of the OpenStack cloud computing project. It offers highly-scalable data storage for measurements and provides access to its data via a REST API.\nIn this lecture, we'll discuss the features the project is offering to its users, and how they can easily be leveraged in any application. In a second part, we'll see how the project has been built to scale, how Python was leveraged and made scalable.",
        "has_abstract": true,
        "description": "",
        "duration": "00:30:00",
        "room": "UD2.120 (Chavanne)",
        "day": "2017-02-05 Sunday",
        "event_type": "Lecture",
        "exact_duration": false,
        "talk_id": "5870"
    },
    {
        "state": "accepted",
        "authors": [
            {
                "email": "bertrandchenal@gmail.com",
                "fullname": "Bertrand Chenal",
                "first_name": "Bertrand",
                "last_name": "Chenal"
            }
        ],
        "title": "Tanker",
        "has_description": true,
        "hour": "13:00",
        "progress": "confirmed",
        "notes": "",
        "subtitle": "Embrace the relational model",
        "abstract": "Tanker goal is to allow easy batch operations without compromising database modeling. For pandas users, it's like DataFrame.to_sql on steroids.",
        "has_abstract": true,
        "description": "The Tanker inception is based on two strong observations (not\nparticularly new):\n\n- The object-relation mapping in so called libraries is sometimes\n  source of performance and semantic difficulties, especially with\n  queries involving multiple joins. On the other hand, the relational\n  model is both powerful and simple, and there are no reason not to\n  expose it to the Python world.\n\n- When working with external data sources, we are often faced with the\n  challenge of matching those records with the database content. We have to\n  know which record is new, which has been updated, etc. We also often\n  have to de-normalize content and map it with a (hopefully)\n  well-designed and 3NF schema.\n\nThis presentation will show how Tanker answers those two aspects, how\nit was inspired by existing libraries and how it is currently used in\nproduction applications.",
        "duration": "00:30:00",
        "room": "H.1308 (Rolin)",
        "day": "2017-02-04 Saturday",
        "event_type": "",
        "exact_duration": false,
        "talk_id": "5679"
    },
    {
        "state": "accepted",
        "authors": [
            {
                "email": "julien@tayon.net",
                "fullname": "Julien Tayon",
                "first_name": "Julien",
                "last_name": "Tayon"
            }
        ],
        "title": "The power of duck typing and linear algrebra ",
        "has_description": true,
        "hour": "11:30",
        "progress": "confirmed",
        "notes": "Slides are to be done.\n\nCode is made and testable (archery, yahi, vectordict are already in pypi) with even applications using it\n\n(like http://pypi-ranking.info/module/pypi-stat using pypi-stat)",
        "subtitle": "How linear algebra and python make a good fit",
        "abstract": "Algebraic operator are every where in python. + = * / \nDict are every where in python. \n\nWhat can we achieve by combining both of them? \n\nA self taught mad scientist tried for you and the results are pretty impressive",
        "has_abstract": true,
        "description": "Introduction\n\nAlgebra is a wonderful abstraction that make the infamous 2D point example of a class or nameddict useless when you have complex data type (that is HW accelerated on Intel CPU). \n\n\nI Algebra 101 : it is all about consistency between symbol and behaviour\n\nSimple: Is something consistent with linear algebra?\nit requires 17 simple unit tests suffice to say so\n\nSo just let makes a test this rules are followed, and then a class that applies these behaviours and we have implemented it.\n\nII I have linear algebra behaviour. How useful can it e? \n\nWell, you have basic data type like { x: 1, y :2, z :3 } that is actually behaving like an euclidean vector.\n\nIf an object is a MutableMapping thus we can create a universal operator for saying how  much an object «looks like» another one.\nPractical use : \n- finding doublons in database;\n- text matching (after a pass of ntlk + word counters);\n- pattern fitting;\n...\n\nThat is the basis of Textual indexation and profiling (it is not only for evil purpose)\nhttps://github.com/jul/ADictAdd_iction/blob/master/example/cos_demo.py\n\n\nIII State of the art of 2 working POC how to use MutableMapping (dict) and super\n\nMost of the operation tested here\nhttps://github.com/jul/ADictAdd_iction/\n\nImplementation as a trait here\nhttps://github.com/jul/archery\n\nBasically it works BUT : \n\n1) it is hard : with archery I stumbled on super\n2) with VectorDict (obsolete) it lacks of genericity and the code is clumsy\n3) python 2 div behaviour was screwing this (and since these library were relying on base operator, I got biten)\n\nPrepare to throw 2 away\n\nIV the future\n\nMaybe proposing a PEP :) because consistent behaviour of operators cand be a great idea (see PEP on matrix multiplication)\n\n\nA chain is as strong as its weakest link : if a lib is based on composing the python based operator, the algebra will be as consistent as the CORE behaviour of the operator in the language. \n\nConclusion\n\nAlgebra is a powerful abstraction that is still underused.\n\nPossible development :\n- Rieman/Hermitian algebra: using the power of the math used in Quantum Mechanics/relativity and python in the same fashion\n- Using Quaternion to have quirkless rotation in euclidean 3D...",
        "duration": "00:30:00",
        "room": "H.1308 (Rolin)",
        "day": "2017-02-04 Saturday",
        "event_type": "",
        "exact_duration": false,
        "talk_id": "5759"
    },
    {
        "state": "accepted",
        "authors": [
            {
                "email": "mansimarkaur.mks@gmail.com",
                "fullname": "Mansimar Kaur",
                "first_name": "Mansimar",
                "last_name": "Kaur"
            }
        ],
        "title": "Webpush notifications for Kinto",
        "has_description": true,
        "hour": "12:30",
        "progress": "confirmed",
        "notes": "",
        "subtitle": "",
        "abstract": "After introducing the Kinto project I am working on, I will explain why push notifications can be useful in the web environment and how I integrated the web push API in Python in Kinto as well as on the client using service workers.",
        "has_abstract": true,
        "description": "What is Kinto?\nKinto is a minimalist JSON storage service with synchronisation and sharing abilities. It is easy to use and to self-host.\nKinto is used and developed at Mozilla and released under the Apache v2 licence.\n\nWhy use Kinto?\nKinto lets you focus on writing great user-facing interfaces and takes care of storing, sharing and synchronizing your application state with multiple devices or users.\nIt is often a big deal for developers to develop web APIs that handle CORS, are secure, respect users privacy by supporting encryption when building applications that work offline, store data remotely, and synchronise across devices. Existing solutions either rely on big corporations that crave user data, or require a non-trivial amount of time and expertise to develop a new server for every new project.\nWe want to help developers focus on their business logic and value proposition, and we don’t want the challenge of storing user data or developing backends to get in their way. The path between a new idea and deploying to production should be short!\nAlso, we are firm believers of the fact that data belongs to users, and not necessarily to the application authors. Applications should be decoupled from the storage location, and users should be able to choose where their personal data is stored.\nThe backend can often be universal, generic and reusable. We envision mutualisation of services and self-hosting: the backend is deployed, secured and scaled only once for several applications, which is amazing!\n\nWhy Web Push?\nPush notifications allow users to opt-in to timely updates from the sites they love and allow you to effectively re-engage them with not only customized and engaging content  but also enable real time interactions with other users of the application, realtime updates and real time data sharing through websockets\nWith Web Push, the notification payload is encrypted by the server sending the notification which makes it really secure and privacy aware.\nWeb push is a browser API feature so that you don't need to pay or to deploy anything on the server side to have it working out of the box.\n\n\nHOW TO PUSH:\n\nWhat is a service worker?\nA service worker is a worker working in the background of your browser that can handle events for a given origin and path.\nIt takes the form of a JavaScript file that can control the web page/site it is associated with.\nThey will also allow handling of push notification events and background sync APIs.\nService workers keep working after the page or website is closed and between browser restarts.\n\nHow to use push notifications?\nOn the client side, it means to setup a service worker and to get a subscription for the user browser.\nThe resulting PushSubscription includes all the information that the application needs to be able to send a push message: an endpoint and the encryption key needed for authenticating and encrypting the data.\n\nWhat is the Kinto Push Service?\nIn the Kinto use case, all users of the same web application will probably want to receive notifications informing them about the creation, updation or deletion of a collection or a record from another device.\nEach device will have its own subscription endpoint and encryption key and the payload will need to be sent to each one of them.\nMy project was about creating a service that can handle subscriptions management and notification broadcast for a given channel.\nWhen the web application starts, it will start a service worker that will be configured to receive push notification and sent them back to all the active browser pages of the web application.\nThe application will call the push service to register the push subscription on some events.\nA Kinto plugin will be triggered each time the application collection changes and it will call the ‘send the notifications’ on the push service channel.\nThe push service will get the notification, encrypt it and publish it to all the subscriptions for that user.\n\nRole of the PushAPI:\n- So, once you’ve got the permission for notifs, registered the service worker and suscribed to push notifs! Congratulations, major breakthrough has been achieved already.\n- Send the endpoint associated with the subscription and generate a client public key (PushSubscription.endpoint and PushSubscription.getKey()) to the server so it can send push message when required. \n- Using the Channel Messaging API set up a new message channel (MessageChannel.MessageChannel()) to communicate with the service worker and by calling Worker.postMessage() on the service worker, in order to open up the communication channel.\n- On the server side, store the endpoint and any other required details so they are available when a push message needs to be sent to a push subscriber. In a production app, it needs to be made sure that these details are kept hidden, so malicious parties can't steal endpoints and spam subscribers with push messages.\n- To send a push message, an HTTP POST is sent to the endpoint URL. The request must include a TTL header that limits how long the message should be queued if the user is not online. To include payload data in the request, it must be encrypted (which involves the client public key). Encryption is a complex process, so we can choose to use libraries which handles all the hard work.",
        "duration": "00:30:00",
        "room": "H.1308 (Rolin)",
        "day": "2017-02-04 Saturday",
        "event_type": "Lecture",
        "exact_duration": false,
        "talk_id": "5667"
    }

    ]
}
